#-------------------------------------------------------- Imports nÃ©cessaires ---------------------------------------------------
import pandas as pd
import seaborn as sns
import plotly.express as px
import matplotlib.pyplot as plt
import plotly.io as pio
import sklearn
import warnings
from scipy.special import expit, logit
import sksurv.datasets
import numpy as np
import joblib
import streamlit as st
import os
from sklearn.cluster import DBSCAN
import urllib.request
import json
import matplotlib
import plotly.graph_objects as go
import xgboost as xgb
from xgboost import XGBRegressor
from xgboost import XGBClassifier
from xgboost import DMatrix
from xgboost import train
from lifelines import CoxPHFitter
from itertools import product
from tqdm import tqdm
from xgbse import XGBSEKaplanNeighbors
from xgbse.converters import convert_to_structured
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.exceptions import UndefinedMetricWarning
from sklearn import set_config
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import ParameterGrid
from sksurv.datasets import load_breast_cancer
from sksurv.metrics import cumulative_dynamic_auc
from sksurv.metrics import concordance_index_censored
from sksurv.linear_model import CoxnetSurvivalAnalysis, CoxPHSurvivalAnalysis
from sksurv.preprocessing import OneHotEncoder
from sksurv.util import Surv


from sksurv.ensemble import GradientBoostingSurvivalAnalysis


warnings.filterwarnings("ignore", category=UndefinedMetricWarning)
set_config(display="text")


#_________________________________________________# Configuration de la page_______________________________________________________
st.set_page_config(page_title="Projet Incendies", layout="wide")

#_________________________________________________# Sidebar de navigation_________________________________________________
st.sidebar.title("Navigation")
page = st.sidebar.radio("Aller Ã ", [
    "Accueil",
    "Notre Projet",
    "Exploration des donnÃ©es",
    "RÃ©sultats des modÃ¨les",
    
])
#________________________________________________________# Footer#_____________________________________________________________
def show_footer():
    st.markdown("---")
    st.markdown("Projet rÃ©alisÃ© dans le cadre de la formation Data Scientist. Â© 2025")
#_________________________________________________# Chargement DATASET (modÃ¨le)#_______________________________________________
@st.cache_data
def load_model_data():
    url = "https://projet-incendie.s3.eu-west-3.amazonaws.com/dataset_modele_decompte.csv"
    try:
        df = pd.read_csv(url)
        for col in df.columns:
            if "date" in col.lower():
                df[col] = pd.to_datetime(df[col], errors="coerce", dayfirst=True)
        return df
    except Exception as e:
        st.error(f"âŒ Erreur lors du chargement des donnÃ©es : {e}")
        return pd.DataFrame()
#_________________________________________________# Chargement des donnÃ©es d'incendies et de coordonnÃ©es#_______________________________________
@st.cache_data
def load_data():
    url_incendies = 'https://projet-incendie.s3.eu-west-3.amazonaws.com/Incendies_2006_2024.csv'
    return pd.read_csv(url_incendies, sep=';', encoding='utf-8', skiprows=3)

@st.cache_data
def load_coords():
    url_coords = 'https://projet-incendie.s3.eu-west-3.amazonaws.com/coordonnees_villes.csv'
    return pd.read_csv(url_coords, sep=',', encoding='utf-8')

@st.cache_data
def load_df_merge():
    url = 'https://projet-incendie.s3.eu-west-3.amazonaws.com/historique_incendies_avec_coordonnees.csv'
    return pd.read_csv(url, sep=';', encoding='utf-8')
#------------------------------------------------------- ----------------Notre produit#_________________________________________________
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import warnings
from sklearn.exceptions import UndefinedMetricWarning
from sklearn import set_config
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from xgboost import XGBRegressor, DMatrix, train as xgb_train
from lifelines import CoxPHFitter
from sksurv.util import Surv
from sksurv.metrics import concordance_index_censored

warnings.filterwarnings("ignore", category=UndefinedMetricWarning)
set_config(display="text")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) FONCTION DE CHARGEMENT DU CSV BRUT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(show_spinner="ğŸ”„ TÃ©lÃ©chargement du CSVâ€¦", ttl=None)
def load_raw_data() -> pd.DataFrame:
    url = (
        "https://projet-incendie.s3.eu-west-3.amazonaws.com/"
        "dataset_modele_decompte.csv"
    )
    return pd.read_csv(url, sep=";")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) FONCTION Dâ€™ENTRAÃNEMENT + PRÃ‰DICTIONS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner="âš™ï¸ EntraÃ®nement du modÃ¨leâ€¦", ttl=None)
def train_model_and_predict(df_raw: pd.DataFrame) -> pd.DataFrame:
    """Retourne df_map prÃªt pour la carte avec les colonnes
       proba_7j, proba_30j, â€¦, proba_180j."""
    # a) Nettoyage
    df = df_raw.copy()
    df = df.rename(columns={"Feu prÃ©vu": "event", "dÃ©compte": "duration"})
    df["event"] = df["event"].astype(bool)
    df["duration"] = df["duration"].fillna(0)

    # b) Features
    features = [
        "moyenne precipitations mois", "moyenne temperature mois",
        "moyenne evapotranspiration mois", "moyenne vitesse vent annÃ©e",
        "moyenne vitesse vent mois", "moyenne temperature annÃ©e",
        "RR", "UM", "ETPMON", "TN", "TX", "Nombre de feu par an",
        "Nombre de feu par mois", "jours_sans_pluie", "jours_TX_sup_30",
        "ETPGRILLE_7j", "compteur jours vers prochain feu",
        "compteur feu log", "AnnÃ©e", "Mois",
        "moyenne precipitations annÃ©e", "moyenne evapotranspiration annÃ©e",
    ]
    features = [f for f in features if f in df.columns]

    # c) split + Surv
    y_struct = Surv.from_dataframe("event", "duration", df)
    X_train, X_test, y_train, y_test = train_test_split(
        df[features], y_struct, test_size=0.3, random_state=42
    )
    ev_train, du_train = y_train["event"], y_train["duration"]
    ev_test, du_test = y_test["event"], y_test["duration"]

    # d) Pipeline XGBSurv
    pipe = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()),
        ("xgb", XGBRegressor(
            objective="survival:cox",
            n_estimators=100,
            learning_rate=0.05,
            max_depth=3,
            tree_method="hist",
            random_state=42,
        )),
    ])
    pipe.fit(X_train, du_train, xgb__sample_weight=ev_train)

    # e) Affiche C-index dans la sidebar
    log_hr_test = pipe.predict(X_test)
    c_index = concordance_index_censored(ev_test, du_test, log_hr_test)[0]
    st.sidebar.write(f"**C-index (test)** : {c_index:.3f}")

    # f) Estimation du baseline hazard (Cox factice)
    df_fake = pd.DataFrame({
        "duration": du_train,
        "event": ev_train,
        "const": 1,
    })
    dmat = DMatrix(df_fake[["const"]])
    dmat.set_float_info("label", df_fake["duration"])
    dmat.set_float_info("label_lower_bound", df_fake["duration"])
    dmat.set_float_info("label_upper_bound", df_fake["duration"])
    dmat.set_float_info("weight", df_fake["event"])
    bst_fake = xgb_train(
        params={
            "objective": "survival:cox",
            "eval_metric": "cox-nloglik",
            "learning_rate": 0.1,
            "max_depth": 1,
            "verbosity": 0,
        },
        dtrain=dmat,
        num_boost_round=100,
    )
    log_hr_fake = bst_fake.predict(dmat)

    df_risque = pd.DataFrame({
        "duration": du_train,
        "event": ev_train,
        "log_risque": log_hr_fake + np.random.normal(0, 1e-4, size=len(log_hr_fake)),
    })
    cph = CoxPHFitter()
    cph.fit(df_risque, duration_col="duration", event_col="event", show_progress=False)

    baseline_cumhaz = cph.baseline_cumulative_hazard_

    def S0(t: int) -> float:
        """Survie de base S0(t) = exp(-H0(t))."""
        idx = baseline_cumhaz.index
        if t in idx:
            H0 = baseline_cumhaz.loc[t].values[0]
        else:
            H0 = baseline_cumhaz.loc[idx[idx <= t]].iloc[-1, 0]
        return float(np.exp(-H0))

    horizons = {7: "proba_7j", 30: "proba_30j", 60: "proba_60j",
                90: "proba_90j", 180: "proba_180j"}

    log_hr_all = pipe.predict(df[features])
    HR = np.exp(log_hr_all)

    for t, col in horizons.items():
        df[col] = 1 - (S0(t) ** HR)   # P(event â‰¤ t)

    df_map = df[["latitude", "longitude", "ville"] + list(horizons.values())].copy()
    return df_map

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) AFFICHAGE SUR LA PAGE Â« Accueil Â»
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if page == "Accueil":
    st.title("Carte du risque dâ€™incendie en Corse")

    df_raw = load_raw_data()
    df_map = train_model_and_predict(df_raw)

    horizons_lbl = {
        "7 jours":  "proba_7j",
        "30 jours": "proba_30j",
        "60 jours": "proba_60j",
        "90 jours": "proba_90j",
        "180 jours": "proba_180j",
    }
    choix = st.radio(
        "Choisis lâ€™horizon temporel :",
        list(horizons_lbl.keys()),
        horizontal=True,
        index=0,
    )
    col_proba = horizons_lbl[choix]

    # Palette dynamique
    vmax = float(df_map[col_proba].max())
    fig = px.scatter_mapbox(
        df_map,
        lat="latitude",
        lon="longitude",
        hover_name="ville",
        hover_data={col_proba: ":.2%"},
        color=col_proba,
        color_continuous_scale="YlOrRd",  # jaune â†’ orange â†’ rouge
        range_color=(0.0, vmax),
        zoom=7,
        height=650,
    )
    fig.update_layout(
        mapbox_style="open-street-map",
        margin=dict(l=0, r=0, t=0, b=0),
        coloraxis_colorbar=dict(title="ProbabilitÃ©", tickformat=".0%"),
    )

    st.subheader(f"Risque dâ€™incendie â€“ horizon **{choix}**")
    st.plotly_chart(fig, use_container_width=True)

# ---------------------------------------------------------------Carte des casernes de pompiers#______________________________________________
from branca.element import Template, MacroElement  # Import nÃ©cessaire

import folium
from folium import DivIcon
from streamlit_folium import st_folium

if page == "Accueil":

    # Chargement des donnÃ©es des casernes
    df_casernes = pd.read_csv(
        'https://projet-incendie.s3.eu-west-3.amazonaws.com/casernes_corses.csv',
        sep=',',
        encoding='utf8'
    )

    # Nettoyage des coordonnÃ©es
    df_casernes['latitude'] = df_casernes['latitude'].astype(str).str.replace(',', '.').astype(float)
    df_casernes['longitude'] = df_casernes['longitude'].astype(str).str.replace(',', '.').astype(float)
    df_casernes = df_casernes.dropna(subset=['latitude', 'longitude'])

    # CatÃ©gorisation des casernes
    df_casernes['categorie'] = np.select(
        [
            df_casernes['nom'].str.contains('centre', case=False, na=False),
            df_casernes['nom'].str.contains('base', case=False, na=False),
            df_casernes['nom'].str.contains('SSLIA', case=False, na=False),
            df_casernes['nom'].str.contains('citerne', case=False, na=False),
            df_casernes['nom'].str.contains('borne', case=False, na=False),
        ],
        [
            "Centre d'incendie et de secours",
            'Base forestiÃ¨re',
            'SSLIA (aÃ©rodromes)',
            'Citerne',
            'Borne incendie'
        ],
        default='Autre'
    )

    # Dictionnaire d'emojis
    emoji_legende = {
        "Centre d'incendie et de secours": "ğŸš’",
        "Base forestiÃ¨re": "ğŸŒ²",
        "SSLIA (aÃ©rodromes)": "âœˆï¸",
        "Citerne": "ğŸ’¦"
    }

    # Carte centrÃ©e sur la Corse
    m = folium.Map(location=[42.0396, 9.0129], zoom_start=8)

    for _, row in df_casernes.iterrows():
        emoji = emoji_legende.get(row['categorie'], 'â“')
        folium.Marker(
            location=[row['latitude'], row['longitude']],
            popup=f"{emoji} {row['nom']}",
            icon=DivIcon(html=f"""<div style="font-size:24px">{emoji}</div>""")
        ).add_to(m)

    # LÃ©gende HTML
    legend_html = """
    {% macro html(this, kwargs) %}
    <div style="
        position: fixed; 
        bottom: 50px; left: 50px; width: 280px; 
        background-color: white;
        border: 2px solid grey; 
        z-index: 9999; 
        font-size: 14px;
        color: black;
        padding: 10px;
        border-radius: 10px;
        box-shadow: 2px 2px 6px rgba(0,0,0,0.3);
    ">
    <b>ğŸ“˜ LÃ©gende</b><br>
    ğŸš’ Centre d'incendie et de secours<br>
    ğŸŒ² Base forestiÃ¨re<br>
    âœˆï¸ SSLIA (aÃ©rodromes)<br>
    ğŸ’¦ Citerne<br>
    </div>
    {% endmacro %}
    """

    legend = MacroElement()
    legend._template = Template(legend_html)

    m.get_root().add_child(legend)

    st.subheader("ğŸ—ºï¸ Carte des casernes et Ã©quipements de lutte contre les incendies")
    st_folium(m, width=1000, height=800)    
#----------------------------------------------------------------------Page Notre Projet---------------------------------------------------
if page == "Notre Projet":
    st.title("ğŸ”¥ Projet Analyse des Incendies ğŸ”¥")

    st.subheader(" ğŸ“Š Contexte")
    st.subheader("ğŸŒ²La forÃªt franÃ§aise en chiffres")

    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown("""
La France est le 4áµ‰ pays europÃ©en en superficie forestiÃ¨re, avec **17,5 millions dâ€™hectares** en mÃ©tropole (32â€¯% du territoire) et **8 millions** en Guyane.
Au total, les forÃªts couvrent environ **41â€¯%** du territoire national.

- **75â€¯%** des forÃªts sont privÃ©es (3,5 millions de propriÃ©taires).
- **16â€¯%** publiques (collectivitÃ©s).
- **9â€¯%** domaniales (Ã‰tat).

La forÃªt franÃ§aise est un rÃ©servoir de biodiversitÃ© :  
- **190 espÃ¨ces dâ€™arbres** (67â€¯% feuillus, 33â€¯% conifÃ¨res).  
- **73 espÃ¨ces de mammifÃ¨res**, **120 dâ€™oiseaux**.  
- Environ **30â€¯000 espÃ¨ces** de champignons et autant dâ€™insectes.  
- **72â€¯%** de la flore franÃ§aise se trouve en forÃªt.

Les forÃªts franÃ§aises absorbent environ **9â€¯%** des Ã©missions nationales de gaz Ã  effet de serre, jouant un rÃ´le crucial dans la lutte contre le changement climatique.

Le Code forestier encadre leur gestion durable pour protÃ©ger la biodiversitÃ©, lâ€™air, lâ€™eau et prÃ©venir les risques naturels.
          """)

if page == "Notre Projet":
    st.header("ğŸ”¥ Corse : Bilan Campagne Feux de ForÃªts 2024")

    # Tabs par grande section
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ“Œ Contexte", "ğŸ› ï¸ PrÃ©vention", "ğŸš’ Moyens", "ğŸ“Š Statistiques",
        "ğŸ” Causes", "ğŸ” EnquÃªtes"
    ])

    with tab1:
        with st.expander("ğŸ“Œ Contexte gÃ©nÃ©ral"):
            st.markdown("""
- **80 %** de la Corse est couverte de forÃªts/maquis â†’ **fort risque incendie**  
- **2023-2024** : la plus chaude et la plus sÃ¨che jamais enregistrÃ©e  
- **714 mm** de pluie sur lâ€™annÃ©e (**78 %** de la normale)  
- **FaÃ§ade orientale** : seulement **30 %** des prÃ©cipitations normales
            """)

    with tab2:
        with st.expander("ğŸ› ï¸ PrÃ©vention & Investissements"):
            st.markdown("""
- **1,9 million â‚¬** investis en 2023-2024 par lâ€™Ã‰tat (jusquâ€™Ã  80 % de financement)  
- Travaux financÃ©s :  
  - Pistes DFCI/DECI (Sorio di Tenda, Oletta, Ãle-Rousseâ€¦)  
  - Citernes souples & points dâ€™eau  
  - Drones, camÃ©ras thermiques, logiciels SIG  
  - VÃ©hicules pour rÃ©serves communales
            """)

    with tab3:
        with st.expander("ğŸš’ Moyens dÃ©ployÃ©s"):
            st.markdown("""
- Jusquâ€™Ã  **500 personnels mobilisables**  
- **168 sapeurs-pompiers SIS2B**, **261 UIISC5**, forestiers-sapeurs, gendarmerie, ONFâ€¦  
- Moyens aÃ©riens :  
  - **1 hÃ©lico**, **2 canadairs** Ã  Ajaccio  
  - **12 canadairs** + **8 Dashs** nationaux en renfort
            """)

    with tab4:
        with st.expander("ğŸ“Š Statistiques Feux Ã‰tÃ© 2024"):
            st.markdown("""
- **107 feux** recensÃ©s (~9/semaine)  
- **130 ha** brÃ»lÃ©s dont :  
  - 83 % des feux <1 ha : **5,42 ha**  
  - 4 gros feux >10 ha : **72,84 ha**  
  - Linguizetta (**22,19 ha**), Oletta (**18,9 ha**), Pioggiola (**18,75 ha**), Tallone (**13 ha**)  
- Depuis janvier 2024 : **285 feux** pour **587 ha**  
- Feu majeur Ã  Barbaggio : **195 ha** (33 % du total annuel)
            """)

    with tab5:
        with st.expander("ğŸ” Causes des feux (38 cas identifiÃ©s)"):
            st.markdown("""
- **11** : foudre  
- **8** : Ã©cobuages  
- **6** : malveillance  
- **5** : accidents  
- **4** : mÃ©gots de cigarette  
            """)

        with st.expander("âš ï¸ PrÃ©vention = prioritÃ© absolue"):
            st.markdown("""
- **90 %** des feux ont une origine humaine  
- Causes principales : **imprudences** (mÃ©gots, BBQ, travaux, Ã©cobuagesâ€¦)
            """)

    with tab6:
        with st.expander("ğŸ” EnquÃªtes & Surveillance"):
            st.markdown("""
- **20 incendies** Ã©tudiÃ©s par la Cellule Technique dâ€™Investigation (CTIFF)  
- Ã‰quipes mobilisÃ©es : **7 forestiers**, **15 pompiers**, **21 forces de lâ€™ordre**  
- **Fermeture de massif** enclenchÃ©e 1 seule fois : forÃªt de Pinia
            """)
#---------------------------------------------------Equipe du projet---------------------------------------------------
    st.subheader("ğŸ‘¨â€ğŸ’» Ã‰quipe du projet")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.image("images/Faycal_Belambri.jpg", width=150)
        st.markdown("**FayÃ§al Belambri**\n\nData Scientist\n\nSpÃ©cialiste App Streamlit et visualisation")
    with col2:
        st.image("images/Joel_Termondjian.jpg", width=150)  
        st.markdown("**JoÃ«l Termondjian**\n\nData Scientist\n\nResponsable des donnÃ©es\n\nPreprocessing\n\nData Enagineering")
    with col3:
        st.image("images/Marc_Barthes.jpg", width=150)
        st.markdown("**Marc Barthes**\n\nData Scientist\n\nML Engineer\n\nExpert en modÃ¨les de prÃ©diction")
#---------------------------------------------------Notre Objectif --------------------------------------------------------
  
    st.subheader("ğŸ¯ Notre Objectif")
    st.markdown("""
Dans un contexte de **changement climatique** et de **risques accrus dâ€™incendies de forÃªt**, notre Ã©quipe a dÃ©veloppÃ© un projet innovant visant Ã  **analyser et prÃ©dire les zones Ã  risque dâ€™incendie** en France, avec un focus particulier sur la **Corse**.
    """)
#---------------------------------------------------Obectifs du projet---------------------------------------------------
    col1, col2 = st.columns([1, 1])
    with col1:
        st.subheader("ğŸ” Exploration des donnÃ©es")
        st.markdown("""
- âœ… **Ã‰volution du nombre dâ€™incendies**, rÃ©partition par mois et par causes.
- âœ… **Cartographie interactive** des incendies sur tout le territoire.
- âœ… **Analyse des clusters** grÃ¢ce Ã  DBSCAN pour identifier les zones les plus Ã  risque.
        """)

    with col2:
        st.subheader("ğŸ“ˆ ModÃ¨les prÃ©dictifs")
        st.markdown("""
- âœ… **Comparaison des modÃ¨les** : Random Forest, XGBoost, analyse de survie.
- âœ… **PrÃ©diction des zones Ã  risque** avec visualisation sur carte.
- âœ… Fourniture d'un **outil dÃ©cisionnel** pour les autoritÃ©s et les services de gestion des risques.
        """)

    st.subheader("ğŸ“˜ DÃ©finition de l'analyse de survie (Survival Analysis")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.markdown("### ğŸ§  Quâ€™est-ce que lâ€™analyse de survie ?")
        st.markdown("""
Lâ€™**analyse de survie** (ou **Survival Analysis**) est une mÃ©thode statistique utilisÃ©e pour **modÃ©liser le temps avant quâ€™un Ã©vÃ©nement se produise**, comme :
- ğŸ”¥ un incendie,
- ğŸ¥ un dÃ©cÃ¨s,
- ğŸ“‰ une rÃ©siliation dâ€™abonnement,
- ğŸ§¯ une panne.
""")

    with col2:
        st.markdown("### ğŸ“Œ Objectif :")
        st.markdown("""
> Estimer la **probabilitÃ© quâ€™un Ã©vÃ©nement ne se soit pas encore produit** Ã  un instant donnÃ©.
""")

    with col3:
        st.markdown("### ğŸ”‘ Concepts fondamentaux : ")
        st.markdown("""
- â³ **Temps de survie (`T`)** : temps Ã©coulÃ© jusquâ€™Ã  lâ€™Ã©vÃ©nement.
- ğŸ¯ **Ã‰vÃ©nement** : le phÃ©nomÃ¨ne quâ€™on cherche Ã  prÃ©dire (feu, panne, dÃ©cÃ¨s...).
- â“ **Censure** : lâ€™Ã©vÃ©nement **nâ€™a pas encore eu lieu** durant la pÃ©riode dâ€™observation.
- ğŸ“‰ **Fonction de survie `S(t)`** : probabilitÃ© de "survivre" aprÃ¨s le temps `t`.
- âš ï¸ **Fonction de risque `h(t)`** : probabilitÃ© que lâ€™Ã©vÃ©nement se produise **immÃ©diatement aprÃ¨s `t`**, sachant quâ€™il ne sâ€™est pas encore produit.
""")
    
    with col4:
        st.markdown ("### ğŸ§ª Exemples dâ€™applications :")
        st.markdown("""
| Domaine | Exemple |
|--------|---------|
| ğŸ”¥ Incendies | Quand un feu va-t-il se dÃ©clarer ? |
| ğŸ¥ SantÃ© | Combien de temps un patient survivra aprÃ¨s traitement ? |
| ğŸ“‰ Marketing | Quand un client risque-t-il de partir ? |
| ğŸ§‘â€ğŸ’¼ RH | Quand un salariÃ© quittera-t-il lâ€™entreprise ? |

""")

    show_footer()

#---------------------------------------------------# Page EDA  -----------------------------------------------------------------

if page == "Exploration des donnÃ©es":
    st.title("ğŸ—ºï¸ Visualisation des incendies entre 2006 et 2024")

    df = load_data()
    coords = load_coords()
    df_merge = load_df_merge()

    st.subheader("AperÃ§u des coordonnÃ©es des villes")

    fig = px.scatter_map(
        coords, 
        lat="latitude", 
        lon="longitude", 
        hover_name="ville",
        height=800,
        zoom=5,
        map_style="carto-positron",
        title="Carte interactive des communes (coordonnÃ©es)"
    )
    st.plotly_chart(fig, use_container_width=True)

#---------------------------------------------------# DBSCAN Clustering---------------------------------------------------
    st.subheader("ğŸ”¥ DÃ©tection des clusters d'incendies avec DBSCAN")

    commune_counts = df_merge.groupby(['Nom de la commune', 'latitude', 'longitude']).size().reset_index(name='frequence')
    df_expanded = commune_counts.loc[commune_counts.index.repeat(commune_counts['frequence'])].reset_index(drop=True)

    X = df_expanded[['latitude', 'longitude']]
    coords_rad = np.radians(X)
    kms_per_radian = 6371.0088
    eps_km = 5
    eps = eps_km / kms_per_radian

    db = DBSCAN(eps=eps, min_samples=20, metric='haversine').fit(coords_rad)
    df_expanded['cluster'] = db.labels_

    clustered_data = df_expanded[df_expanded['cluster'] != -1]

    fig = px.scatter_map(
        clustered_data,
        lat="latitude",
        lon="longitude",
        color="cluster",
        hover_name="Nom de la commune",
        zoom=5,
        height=900,
        title="ğŸ”¥ Clusters d'incendies en France (2006-2024) dÃ©tectÃ©s par DBSCAN",
        map_style="carto-positron"
    )
    st.plotly_chart(fig, use_container_width=True)


    #---------------------------------------------------Histogramme mensuel#---------------------------------------------------
    st.title("Comparaison mensuelle des incendies par annÃ©e")

    df_temp = df_merge.copy()
    df_temp['Date'] = pd.to_datetime(df_temp['Date'], errors='coerce')
    df_temp = df_temp.dropna(subset=['Date'])

    df_temp['mois'] = df_temp['Date'].dt.month
    df_temp['annÃ©e'] = df_temp['Date'].dt.year

    mois_abbr = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
    df_temp['mois_nom'] = df_temp['mois'].apply(lambda x: mois_abbr[x - 1])
    df_temp['mois_nom'] = pd.Categorical(df_temp['mois_nom'], categories=mois_abbr, ordered=True)

    df_grouped = df_temp.groupby(['mois_nom', 'annÃ©e']).size().reset_index(name='nombre_feux')

    fig = px.bar(
        df_grouped,
        x='mois_nom',
        y='nombre_feux',
        color='annÃ©e',
        barmode='group',
        title='Comparaison mensuelle des incendies par annÃ©e',
        height=600,
        width=1000
    )
    st.plotly_chart(fig, use_container_width=True)

    show_footer()

    #--------------------------------------------------- Analyse des causes---------------------------------------------------
    causes = df_merge['Nature'].value_counts()
    st.subheader("RÃ©partition des causes d'incendies")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.pie(
        causes.values,
        labels=causes.index,
        autopct='%1.1f%%',
        startangle=140,
        shadow=True,
        explode=[0.05]*len(causes)
    )
    ax.set_title("RÃ©partition des causes d'incendies")
    ax.axis('equal')
    st.pyplot(fig)

#---------------------------------------------------- Nombre total dâ€™incendies par annÃ©e-----------------------------------------

if page == "Exploration des donnÃ©es":
    st.title("Analyse des incendies par annÃ©e ğŸ”¥")

    # Copie du DataFrame
    df_temp = df_merge.copy()

    # Conversion de la colonne Date
    df_temp['Date'] = pd.to_datetime(df_temp['Date'])
    df_temp['annÃ©e'] = df_temp['Date'].dt.year

    # Regroupement par annÃ©e uniquement
    df_grouped = df_temp.groupby('annÃ©e').size().reset_index(name='nombre_feux')

    # CrÃ©ation du graphique en barres
    fig = px.bar(
        df_grouped,
        x='annÃ©e',
        y='nombre_feux',
        title='Nombre total dâ€™incendies par annÃ©e',
        height=600,
        width=1200,
        text='nombre_feux'
    )

    fig.update_xaxes(
        tickmode='linear',
        dtick=1  # une annÃ©e Ã  chaque tick
    )

    fig.update_layout(
        xaxis_title='AnnÃ©e',
        yaxis_title='Nombre de feux',
        xaxis_tickangle=0
    )

    st.plotly_chart(fig)
#---------------------------------------------------- Page Exploration des donnÃ©es -----------------------------------------

if page == "Exploration des donnÃ©es":

#---------------------------------------------------- Les 10 dÃ©partements avec le plus dâ€™incendies -----------------------------------------

    # Copie du DataFrame
    df_temp = df_merge.copy()

    # Regroupement par dÃ©partement
    df_grouped = df_temp.groupby('DÃ©partement').size().reset_index(name='nombre_feux')

    # Classement dÃ©croissant et sÃ©lection du top 10
    df_top10 = df_grouped.sort_values(by='nombre_feux', ascending=False).head(10)

    # Graphique en barres
    fig = px.bar(
        df_top10,
        x='DÃ©partement',
        y='nombre_feux',
        title='Les 10 dÃ©partements avec le plus dâ€™incendies',
        height=600,
        width=1000,
        text='nombre_feux'
    )

    # Fond clair
    fig.update_layout(
        template='plotly_white',
        xaxis_title='DÃ©partement',
        yaxis_title='Nombre de feux',
        xaxis_tickangle=-45,
    )

    # Texte au-dessus des barres
    fig.update_traces(textposition='outside')

    # Affichage dans l'app
    st.plotly_chart(fig)


 #---------------------------------------------------- Les 10 dÃ©partements les plus touchÃ©s -----------------------------------------   

if page == "Exploration des donnÃ©es":

    # ğŸ” VÃ©rification rapide du DataFrame
    if "DÃ©partement" not in df_merge.columns:
        st.error("âŒ La colonne 'DÃ©partement' est absente du DataFrame.")
    elif df_merge.empty:
        st.warning("âš ï¸ Le DataFrame est vide.")
    else:
        # âœ… Copie et nettoyage du DataFrame
        df_temp = df_merge.copy()
        df_temp = df_temp[df_temp['DÃ©partement'].notna()]  # Supprime les lignes sans dÃ©partement

        # ğŸ“Š Regroupement par dÃ©partement
        df_grouped = df_temp.groupby('DÃ©partement').size().reset_index(name='nombre_feux')

        # ğŸ”¢ Total gÃ©nÃ©ral
        total_feux = df_grouped['nombre_feux'].sum()

        # ğŸ” Top 10 des dÃ©partements
        df_top10 = df_grouped.sort_values(by='nombre_feux', ascending=False).head(10)

        # ğŸ“ˆ Calcul des proportions
        df_top10['proportion_totale'] = df_top10['nombre_feux'] / total_feux

        # ğŸ¥§ CrÃ©ation du graphique circulaire
        fig_pie = px.pie(
            df_top10,
            names='DÃ©partement',
            values='nombre_feux',
            title='Les 10 dÃ©partements les plus touchÃ©s (proportion sur le total global)',
        )
        fig_pie.update_traces(textinfo='label+percent')

        # ğŸ“Œ Affichage dans l'app
        st.plotly_chart(fig_pie)

#---------------------------------------------------- Carte des feux par dÃ©partement (2006-2024) ---------------------------------------------------------

if page == "Exploration des donnÃ©es":
    st.subheader("Carte des feux par dÃ©partement (2006-2024)")

    # Copie du dataset
    df_temp = df_merge.copy()

    # Codes dÃ©partements formatÃ©s
    df_temp['DÃ©partement'] = df_temp['DÃ©partement'].astype(str).str.zfill(2)
    df_grouped = df_temp.groupby('DÃ©partement').size().reset_index(name='nombre_feux')

    # Chargement GeoJSON
    url_geojson = 'https://raw.githubusercontent.com/gregoiredavid/france-geojson/master/departements-version-simplifiee.geojson'
    with urllib.request.urlopen(url_geojson) as response:
        departements_geojson = json.load(response)

    # Carte choroplÃ¨the
    fig = px.choropleth(
        df_grouped,
        geojson=departements_geojson,
        locations='DÃ©partement',
        featureidkey='properties.code',
        color='nombre_feux',
        color_continuous_scale='OrRd',
        title='Total des feux par dÃ©partement (2006-2024)',
        labels={'nombre_feux': 'Feux'},
    )

    # Style gÃ©ographique
    fig.update_geos(
        visible=False,
        lataxis_range=[41, 52],
        lonaxis_range=[-5.5, 10],
        showcountries=False,
        showcoastlines=False,
        showland=True,
        landcolor='white',
        fitbounds="locations"
    )

    # Mise en page
    fig.update_layout(
        template='plotly_white',
        width=1000,
        height=700,
        margin=dict(l=0, r=20, t=40, b=0),
        coloraxis_colorbar=dict(
            title="Feux",
            thickness=15,
            len=0.4,
            y=0.5
        )
    )

    # Affichage Streamlit
    st.plotly_chart(fig)
#---------------------------------------------------- Les 10 dÃ©partements avec le plus dâ€™incendies -----------------------------------------
# import plotly.graph_objects as go

# -----------------------------------------------------------
# ğŸ”¥ Top-10 des dÃ©partements par nombre de feux â€“ version GO
# -----------------------------------------------------------
if page == "Exploration des donnÃ©es":
    df_temp = df_merge.copy()
    df_temp["DÃ©partement"] = df_temp["DÃ©partement"].replace(
        {"2A": "2A/2B", "2B": "2A/2B"}
    )

    df_count = (
        df_temp.groupby("DÃ©partement")
        .size()
        .reset_index(name="Nombre de feux")
        .sort_values("Nombre de feux", ascending=False)
        .head(10)
    )

    # â”€â”€ Barres avec labels (Graph Objects)
    fig_top10_feux = go.Figure(
        data=go.Bar(
            x=df_count["DÃ©partement"],
            y=df_count["Nombre de feux"],
            text=df_count["Nombre de feux"].apply(lambda x: f"{x:,}"),
            textposition="outside",
            textfont=dict(size=16, color="#2e2e2e"),  # police foncÃ©e
            marker=dict(
                color="#627CFF",
                line=dict(color="black", width=1.5),
            ),
        )
    )

    # â”€â”€ Mise en page inspirÃ©e de ta Fig 1
    fig_top10_feux.update_layout(
        title="ğŸ”¥ Top 10 des dÃ©partements avec le plus dâ€™incendies",
        title_font_size=28,
        template="plotly_white",                     # fond clair + grille
        plot_bgcolor="rgba(245,248,255,1)",
        paper_bgcolor="rgba(245,248,255,1)",
        margin=dict(l=80, r=80, t=110, b=120),
        font=dict(size=18, color="#2e2e2e"),        # police par dÃ©faut foncÃ©e
        xaxis=dict(
            title="DÃ©partement",
            tickangle=-35,
            tickfont=dict(size=16),
        ),
        yaxis=dict(
            title="Nombre de feux",
            tickformat=",d",
            tickfont=dict(size=16),
        ),
        bargap=0.05,
    )

    st.plotly_chart(fig_top10_feux, use_container_width=True)


#---------------------------------------------------- Page RÃ©sultats des modÃ¨les -----------------------------------------

elif page == "RÃ©sultats des modÃ¨les":
    st.title("ğŸ“ˆ RÃ©sultats des modÃ¨les prÃ©dictifs")
    st.markdown("### Comparaison des modÃ¨les de Survival Analysis")

    #--------------------------------------------------- Tableau codÃ© en dur en Markdown -----------------------------------
    st.markdown("""
    | ModÃ¨le                            | Concordance Index | 
    |-----------------------------------|-------------------|
    | Predict survival fonction (MVP)   | 0.69              |                 
    | XGBOOST survival cox              | 0.809             |      
    """)

    st.markdown("ğŸ‘‰ Le modÃ¨le **XGBOOST survival cox** obtient la meilleure performance globale.")

    show_footer()